name: Daily Event Scraper

on:
  schedule:
    # Run at 6 AM EST every day (11 AM UTC)
    - cron: '0 11 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Clear database
        run: |
          echo "üóëÔ∏è  Clearing database..."
          curl -X POST https://soiree-one.vercel.app/api/refresh \
            -H "Content-Type: application/json" \
            -w "\n%{http_code}\n" \
            -o response.json
          cat response.json
          echo ""

      - name: Run scraper
        run: |
          echo "üåê Starting event scraper..."
          HTTP_CODE=$(curl -X POST https://soiree-one.vercel.app/api/scrape \
            -H "Authorization: Bearer ${{ secrets.SCRAPE_SECRET }}" \
            -H "Content-Type: application/json" \
            -w "%{http_code}" \
            -o scrape-result.json \
            -s)

          echo "HTTP Status: $HTTP_CODE"
          echo "üìä Scrape Results:"
          cat scrape-result.json
          echo ""

          # Check HTTP status
          if [ "$HTTP_CODE" != "200" ]; then
            echo "‚ùå Scrape failed with HTTP $HTTP_CODE"
            exit 1
          fi

          echo "‚úÖ Main scrape completed successfully"

      - name: Scrape The Local Girl (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "üåê Scraping The Local Girl (Direct Node Script)..."
          # Install dependencies if not already (should be cached or fast)
          npm install axios cheerio pg dotenv
          
          # Run the script
          node scripts/scrape-localgirl-direct.js

      - name: Scrape Visit NJ (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "üåê Scraping Visit NJ (Direct Puppeteer Script)..."
          # Install Puppeteer and dependencies
          npm install puppeteer pg dotenv
          
          # Run the script
          node scripts/scrape-visitnj-direct.js

      - name: Scrape Museums (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "üèõÔ∏è  Scraping Museums (MoMA, Guggenheim, AMNH)..."
          # Puppeteer already installed from previous step
          
          # Run the script
          node scripts/scrape-museums-direct.js

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results
          path: |
            response.json
            scrape-result.json
          retention-days: 7
