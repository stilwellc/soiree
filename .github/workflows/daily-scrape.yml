name: Daily Event Scraper

on:
  schedule:
    # Run at 6 AM EST every day (11 AM UTC)
    - cron: '0 11 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Clear database
        run: |
          echo "ğŸ—‘ï¸  Clearing database..."
          curl -X POST https://soiree-one.vercel.app/api/refresh \
            -H "Content-Type: application/json" \
            -w "\n%{http_code}\n" \
            -o response.json
          cat response.json
          echo ""

      - name: Run scraper
        run: |
          echo "ğŸŒ Starting event scraper..."
          HTTP_CODE=$(curl -X POST https://soiree-one.vercel.app/api/scrape \
            -H "Authorization: Bearer ${{ secrets.SCRAPE_SECRET }}" \
            -H "Content-Type: application/json" \
            -w "%{http_code}" \
            -o scrape-result.json \
            -s)

          echo "HTTP Status: $HTTP_CODE"
          echo "ğŸ“Š Scrape Results:"
          cat scrape-result.json
          echo ""

          # Check HTTP status
          if [ "$HTTP_CODE" != "200" ]; then
            echo "âŒ Scrape failed with HTTP $HTTP_CODE"
            exit 1
          fi

          echo "âœ… Main scrape completed successfully"

      - name: Scrape Visit NJ (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "ğŸŒ Scraping Visit NJ (Direct Puppeteer Script)..."
          # Install Puppeteer and dependencies
          npm install puppeteer pg dotenv
          
          # Run the script
          node scripts/scrape-visitnj-direct.js

      - name: Scrape AMNH (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "ğŸ›ï¸  Scraping AMNH (Direct Puppeteer Script)..."
          # Puppeteer already installed from previous step

          # Run the script
          node scripts/scrape-amnh-direct.js

      - name: Scrape The Local Girl (Direct)
        env:
          POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
        run: |
          echo "ğŸŒ Scraping The Local Girl (Puppeteer)..."
          # Puppeteer already installed from Visit NJ step

          # Run the script
          node scripts/scrape-localgirl-direct.js

      # TODO: Re-enable other museum scrapers (MoMA, Guggenheim) once date parsing is fixed
      # - name: Scrape Museums (Direct)
      #   env:
      #     POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
      #   run: |
      #     echo "ğŸ›ï¸  Scraping Museums (MoMA, Guggenheim)..."
      #     node scripts/scrape-museums-direct.js

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-results
          path: |
            response.json
            scrape-result.json
          retention-days: 7
